import{_ as e,o as l,c as s,b as a}from"./app-CQavEA7Q.js";const n={},i=a(`<h1 id="_13-elasticsearch的优化建议" tabindex="-1"><a class="header-anchor" href="#_13-elasticsearch的优化建议"><span>13 Elasticsearch的优化建议</span></a></h1><h2 id="_13-1-硬件选择" tabindex="-1"><a class="header-anchor" href="#_13-1-硬件选择"><span>13.1 硬件选择</span></a></h2><p>Elasticsearch是基于Lucene的，所有的索引和文档数据都是存储在本地的磁盘中，具体路径可在ES配置文件<code>config/elasticsearch.yml</code>中配置，如下：</p><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre class="language-yaml"><code><span class="line"><span class="token comment"># 数据文件</span></span>
<span class="line"><span class="token key atrule">path.data</span><span class="token punctuation">:</span> ./data</span>
<span class="line"><span class="token comment"># 日志文件</span></span>
<span class="line"><span class="token key atrule">path.logs</span><span class="token punctuation">:</span> ./logs</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>磁盘在现代服务器上通常都是瓶颈。Elasticsearch重度使用磁盘，<strong>磁盘的吞吐量越大，节点就越稳定。</strong></p><blockquote><p>优化磁盘I/O的技巧</p></blockquote><ul><li>使用SSD（固态硬盘）</li><li>使用RAID 0（一种硬盘阵列）：读写速度快，能够提高磁盘容量。但是当一快磁盘故障整个就故障了。不要使用镜像或者奇偶校验RAID，因为副本已经提供该功能。</li><li>使用多块硬盘，并允许Elasticsearch通过多个<code>path.data</code>目录配置把数据条带化分配到它们上面。</li><li>不要使用远程挂载的存储，如NFS或者SMB/CIFS</li></ul><h2 id="_13-2-分片策略" tabindex="-1"><a class="header-anchor" href="#_13-2-分片策略"><span>13.2 分片策略</span></a></h2><h3 id="_13-2-1-合理设置分片数" tabindex="-1"><a class="header-anchor" href="#_13-2-1-合理设置分片数"><span>13.2.1 合理设置分片数</span></a></h3><blockquote><p>分片的代价</p></blockquote><ul><li>一个分片的底层即为一个Lucene索引，会消耗一定文件句柄、内存以及CPU运转</li><li>每一个搜索请求都需要命中索引中的一个分片。如果多个分片处于同一个节点，这些分片就会竞争使用相同的资源</li><li>用于计算相关度的词项统计信息是基于分片的。如果分片过多，就会导致很低的相关度</li></ul><blockquote><p>分片遵循的原则</p></blockquote><ul><li><p>控制每个分片占用的磁盘容量不超过ES的最大JVN堆栈空间设置（JVM一般不超过32M，参考下面JVM设置原则）。</p><p><code>栗子</code> 假设索引的总容量在500G左右，那么分片大小在16个左右即可。当然，最好同时考虑原则2</p></li><li><p>分片数一般不要超过节点数的3倍。</p><p><code>说明</code> 一般来书一个节点就是一台物理机。如果分片数打打超过节点数，就会造成一个节点上多个分片，处理在索引时会竞争资源外，一旦该节点故障，即使保持了1个以上的副本，同样有可能导致数据丢失，集群无法恢复。</p></li><li><p>主分片、副本、节点最大数的计算公式如下：</p><p><code>公式</code> 节点数 &lt;= 主分片数 * (副本数 + 1)</p></li></ul><h3 id="_13-2-2-推迟分片分配" tabindex="-1"><a class="header-anchor" href="#_13-2-2-推迟分片分配"><span>13.2.2 推迟分片分配</span></a></h3><p>对于节点瞬时中断的问题，默认情况下，集群会等待<strong>1min</strong>来查看节点是否会重新加入。 如果这个节点在此瞬间重新加入，重新加入的节点会保持现有的分片数据，不会触发新的分片分配。 这样就可以减少Elasticsearch在自动再平衡可用分片时所带来的的极大开销。</p><blockquote><p>延长再均衡时间</p></blockquote><p>通过修改参数<code>delayed_time</code>，延长再均衡时间。可以全局设置，也可以在索引级别修改</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre class="language-text"><code><span class="line">PUT /_all/_settings </span>
<span class="line">{</span>
<span class="line">  &quot;settings&quot;: {</span>
<span class="line">    &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5m&quot; </span>
<span class="line">  }</span>
<span class="line">}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_13-3-路由选择" tabindex="-1"><a class="header-anchor" href="#_13-3-路由选择"><span>13.3 路由选择</span></a></h2><p>当进行文档查询的时候，Elasticsearch是通过如下公式计算得到文档存放的分片：</p><p><code>shard = hash(routing) % number_of_primary_shards</code> 其中，routing默认值是文档id，也可以采用自定义值。</p><ul><li><p><strong>不带routing查询</strong></p><p>在查询时，因为不知道要查询的数据具体在哪个分片上，所以整个过程分为2个步骤</p><ul><li>分发： 请求到达协调节点后，协调节点将查询请求分发到每个分片上</li><li>聚合： 协调节点搜集到每个分片上的查询结果，将查询结果进行排序，然后将结果返回给用户</li></ul></li><li><p><strong>带routing查询</strong></p><p>查询时，可以根据routing信息定位到某个分片查询，不需要查询所有分片。</p></li></ul><h2 id="_13-4-写入速度优化" tabindex="-1"><a class="header-anchor" href="#_13-4-写入速度优化"><span>13.4 写入速度优化</span></a></h2><p>ES默认配置，是综合了数据可靠性、写入速度、搜索实时性等因素。 实际使用时，可以按照实际情况，进行偏向性的优化。</p><blockquote><p>写入速度优化概述</p></blockquote><p>针对搜索性能要求不高，但对写入要求较高的场景，我们需要尽可能的选择恰当的写优化策略。 综合来说，可以考虑一下几个方面来提升索引的性能：</p><ul><li>在集群正常运行的前提下，如果是集群首次批量导入数据时，可以将副本数设置为0，导入完毕后再将副本数调整为正常值，这样副分片就只需要复制，节约了构建索引的时间</li><li>增大Translog flush间隔，目的是降低Iops（即每秒的输入输出量(或读写次数)，是衡量磁盘性能的主要指标之一）、WriteBlock</li><li>增大Index Refresh间隔，以减少I/O，更重要的是减少Segment Merge（段合并）的次数</li><li>善用Bulk请求，调整Bulk线程池和队列</li><li>优化磁盘的任务均匀情况，将shard尽量均匀分布到物理主机的各个磁盘</li><li>优化节点见的任务分布，将任务尽量均匀的发到各个节点</li><li>优化Lucene层的索引建立，以降低CPU和IO，如禁用<code>_all</code>字段</li></ul><blockquote><p>重要概念</p></blockquote><ul><li><code>flush</code>：是指触发lucene commit，也就是将缓存中的数据写入到磁盘，并清空translog日志文件</li><li><code>refresh</code>: 是指从内存到文件系统缓存的过程。此时该文档就可以被搜索到，但是该文档还没有存储到磁盘上，如果机器宕机了，数据就会丢失</li></ul><h3 id="_13-4-1-增大translog-flush间隔" tabindex="-1"><a class="header-anchor" href="#_13-4-1-增大translog-flush间隔"><span>13.4.1 增大Translog flush间隔</span></a></h3><p>默认情况下，translog的持久化策略为每个请求都flush。对应配置如下：</p><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre class="language-yaml"><code><span class="line"><span class="token key atrule">index.translog.durability</span><span class="token punctuation">:</span> request </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这是写入速度的最大因素，但是也只有这样，写操作才有可能是可靠的。</p><p><strong>如果系统能够接受一定概率的数据的丢失</strong>（如，数据写入主分片成功，尚未复制到副本时，主机断电。由于数据既没有刷到Lucene，translog也没有刷入磁盘，恢复时，translog中没有这个数据，导致数据丢失）， 则可以调整translog持久化策略为周期性和一定大小的时候flush。如：</p><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre class="language-yaml"><code><span class="line"><span class="token comment"># async表示translog的刷盘策略按sync_interval配置指定的时间周期进行</span></span>
<span class="line"><span class="token key atrule">index.translog.durability</span><span class="token punctuation">:</span> async</span>
<span class="line"><span class="token comment"># 加大translog刷盘间隔时间。默认为5s，不可低于10ms</span></span>
<span class="line"><span class="token key atrule">index.translog.sync_interval</span><span class="token punctuation">:</span> 120s</span>
<span class="line"><span class="token comment"># （段合并的时候设置）设置当超过一定大小时进行flush。当超过这个大小会导致refresh操作，产生新的Lucene分段。默认值为 512MB</span></span>
<span class="line"><span class="token key atrule">index.translog.flush_threshold_size</span><span class="token punctuation">:</span> 1024mb</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_13-4-2-增大index-refresh间隔" tabindex="-1"><a class="header-anchor" href="#_13-4-2-增大index-refresh间隔"><span>13.4.2 增大Index Refresh间隔</span></a></h3><p>默认情况下索引的refresh_interval为1s，这意味着数据每隔1s就会从es缓存中写入文件系统缓存中，以保证数据可以被搜索到。 每次索引的refresh会产生一个新的Lucene段（即segment），segment在符合一定条件后，会自动合并，因此这会导致频繁的segment merge行为。 如果不需要这么高的搜索实时性，应该降低索引refresh周期。</p><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre class="language-yaml"><code><span class="line"><span class="token key atrule">index.refresh_interval</span><span class="token punctuation">:</span> 120s</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_13-4-3-段合并优化" tabindex="-1"><a class="header-anchor" href="#_13-4-3-段合并优化"><span>13.4.3 段合并优化</span></a></h3><ul><li><p>降低段产生的数量</p><ul><li>增大Index Refresh间隔（见13.4.2小节）</li><li>增大分片的indexing buffer <ul><li>indexing buffer在为doc建立索引时使用，当缓冲满时会刷入磁盘， 生成一个新的segment，这是除refresh_interval刷新索引外，另一个生成新segment的机会。</li><li>每个shard有自己的indexing buffer， 配置修改如下<div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre class="language-yaml"><code><span class="line"><span class="token key atrule">indices.memory.index_buffer_size</span><span class="token punctuation">:</span> 15% <span class="token comment"># 默认为10%，可以适当增大该值 </span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul></li><li>尽量减少文档的更新操作</li></ul></li><li><p>降低最大段的大小，避免较大的段继续参与merge，节省系统资源，但是最终会有多个段</p><ul><li><p>增大<code>index.merge.policy.segments_per_tier</code>，默认为10，值越小表示需要越多的merge。</p><p>另：该值需要大于等于<code>index.merge.policy.max_merge_at_once</code>(表示默认一次最多归并segment的个数，默认为10)</p></li><li><p>减小<code>index.merge.policy.max_merged_segment</code>，默认5GB。当段的大小超过此值后，将不再参与merge操作</p></li></ul></li><li><p>当Index不再有写入操作时，对其进行force merge，最好force merge成1个段。 如此可以提升查询速度，减少内存开销，但是force merge时会消耗大量的I/O、CUP资源</p></li></ul><h3 id="_13-4-4-善用bulk请求" tabindex="-1"><a class="header-anchor" href="#_13-4-4-善用bulk请求"><span>13.4.4 善用Bulk请求</span></a></h3><ul><li>当需要执行批量写操作时，Bulk请求比一个索引请求只写单个文档效率高得多，但是Bulk请求的整体字节数最好避免超过几十兆字节，否则会给内存带来极大压力。</li><li>Bulk线程池和队列的优化：建立索引的过程属于<strong>计算密集型任务</strong>，应使用固定大小的线程池，来不及处理的任务放到队列中。 <ul><li>线程池数：CPU核数 + 1，这也是默认配置，可以避免过多的上下文切换</li><li>队列数：队列数可以适当增加，但是一定要严格控制大小，过大的队列导致较高的GC压力，并可能导致FGC频繁发生</li><li>要注意bulk线程池队列的reject情况，出现reject代表ES的bulk队列已满，客户端收到429错误(TOO_MANY_REQUESTS)。 不可忽略这个异常，否则写入系统的数据会少于预期。即使客户端正确处理了429错误，我们仍然应该尽量避免产生reject。</li></ul></li></ul><h3 id="_13-4-5-单节点磁盘间的任务均衡" tabindex="-1"><a class="header-anchor" href="#_13-4-5-单节点磁盘间的任务均衡"><span>13.4.5 单节点磁盘间的任务均衡</span></a></h3><ul><li><p>首先在配置文件conf/Elasticsearch.yml中为path.data配置多个路径来使用多块磁盘，多磁盘带来的并行写的优势可以增加吞吐量</p></li><li><p>多磁盘写入可能会带来任务不均衡的问题，Elasticsearch在分配shard时，落到各磁盘上的shard可能并不均匀。 这种不均匀可能会导致某些磁盘繁忙，利用率在较长时间内持续达到100%，而某些磁盘可能使用率很低甚至为0，这种不均匀达到一定程度会对写入性能产生负面影响。</p><p>对于此种场景，有两种策略可以考虑：</p><ul><li>简单轮询：在系统初始阶段，简单轮询的效果是最均匀的。</li><li>基于可用空间的动态加权轮询：以可用空间作为权重，在磁盘之间加权轮询</li></ul></li></ul><h3 id="_13-4-6-节点间的任务均衡" tabindex="-1"><a class="header-anchor" href="#_13-4-6-节点间的任务均衡"><span>13.4.6 节点间的任务均衡</span></a></h3><p>为了节点间的任务尽量均衡，数据写入客户端应该把bulk请求轮询发送到各个节点。此时可以 <strong>考虑使用Java API或REST API的bulk接口发送数据</strong>。</p><p>当使用Java API或REST API的bulk接口发送数据时，客户端将会轮询发送到集群节点，节点列表取决于：</p><ul><li>使用Java API时，当设置client.transport.sniff为true（默认为false） 时，列表为所有数据节点，否则节点列表为构建客户端对象时传入的节点列表。</li><li>使用REST API时，列表为构建对象时添加进去的节点。</li></ul><p>在此 <strong>建议使用REST API</strong> ,Java API会在未来的版本中废弃，REST API有良好的版本兼容性好。 理论上，Java API在序列化上有性能优势，但是只有在吞吐量非常大时才值得考虑序列化的开销带来的影响， 通常搜索并不是高吞吐量的业务。</p><p>观察 <code>bulk</code> 请求在不同节点上的处理情况：</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre class="language-text"><code><span class="line">GET _cat/thread_pool</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_13-4-7-优化索引的建立" tabindex="-1"><a class="header-anchor" href="#_13-4-7-优化索引的建立"><span>13.4.7 优化索引的建立</span></a></h3><ul><li><p>自动生成docID，避免es对自定义ID验证操作</p></li><li><p>调整字段Mapping</p><ul><li>减少不必要的字段数量</li><li>将不需要创建索引字段的index属性设置为not_analyzed，对字段不分词或者不建立索引，减少相应的操作，特别是binary类型</li><li>减少字段内容长度</li><li>使用不同的分析器（analyzer），不同分析器之间的运算复杂度也不相同</li></ul></li><li><p>调整_source字段</p><p>_source字段用于存储doc原始数据，对于部分不需要存储的字段，可以使用<code>includes excludes</code>过滤，或者禁用_source，但是一般实际场景不会禁用。</p></li><li><p>禁用_all</p><p>_all中包含所有字段分词后的关键词，作用是可以搜索的时候不指定特定的字段，从所有字段中检索。 从ES6.0之后，_all字段默认不启用。</p></li><li><p>对不需要评分的字段禁用Norms</p><p>Norms字段用于在搜索时计算doc的评分，如果不需要评分，可以将其禁用：</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre class="language-text"><code><span class="line"> &quot;title&quot;: {</span>
<span class="line">      &quot;type&quot;: &quot;string&quot;,</span>
<span class="line">      &quot;norms&quot;: {</span>
<span class="line">          &quot;enabled&quot;: false</span>
<span class="line">      }</span>
<span class="line">  }</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul>`,53),t=[i];function r(c,d){return l(),s("div",null,t)}const o=e(n,[["render",r],["__file","13_Elasticsearch的优化建议.html.vue"]]),u=JSON.parse('{"path":"/static/tang/Elasticsearch/13_Elasticsearch%E7%9A%84%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE.html","title":"13 Elasticsearch的优化建议","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"13.1 硬件选择","slug":"_13-1-硬件选择","link":"#_13-1-硬件选择","children":[]},{"level":2,"title":"13.2 分片策略","slug":"_13-2-分片策略","link":"#_13-2-分片策略","children":[{"level":3,"title":"13.2.1 合理设置分片数","slug":"_13-2-1-合理设置分片数","link":"#_13-2-1-合理设置分片数","children":[]},{"level":3,"title":"13.2.2 推迟分片分配","slug":"_13-2-2-推迟分片分配","link":"#_13-2-2-推迟分片分配","children":[]}]},{"level":2,"title":"13.3 路由选择","slug":"_13-3-路由选择","link":"#_13-3-路由选择","children":[]},{"level":2,"title":"13.4 写入速度优化","slug":"_13-4-写入速度优化","link":"#_13-4-写入速度优化","children":[{"level":3,"title":"13.4.1 增大Translog flush间隔","slug":"_13-4-1-增大translog-flush间隔","link":"#_13-4-1-增大translog-flush间隔","children":[]},{"level":3,"title":"13.4.2 增大Index Refresh间隔","slug":"_13-4-2-增大index-refresh间隔","link":"#_13-4-2-增大index-refresh间隔","children":[]},{"level":3,"title":"13.4.3 段合并优化","slug":"_13-4-3-段合并优化","link":"#_13-4-3-段合并优化","children":[]},{"level":3,"title":"13.4.4 善用Bulk请求","slug":"_13-4-4-善用bulk请求","link":"#_13-4-4-善用bulk请求","children":[]},{"level":3,"title":"13.4.5 单节点磁盘间的任务均衡","slug":"_13-4-5-单节点磁盘间的任务均衡","link":"#_13-4-5-单节点磁盘间的任务均衡","children":[]},{"level":3,"title":"13.4.6 节点间的任务均衡","slug":"_13-4-6-节点间的任务均衡","link":"#_13-4-6-节点间的任务均衡","children":[]},{"level":3,"title":"13.4.7 优化索引的建立","slug":"_13-4-7-优化索引的建立","link":"#_13-4-7-优化索引的建立","children":[]}]}],"git":{"updatedTime":1720499771000,"contributors":[{"name":"文铁铁~","email":"1179131421@qq.com","commits":1}]},"filePathRelative":"static/tang/Elasticsearch/13_Elasticsearch的优化建议.md"}');export{o as comp,u as data};
